{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REIT Stocks (Real Estate Investment Trust) Statistical analyis\n",
    "\n",
    "REITS are an alternative investment option to those that want to invest in real estate, but do not have the funds to buy property or simply do not qualify for mortgage. Reits historically have delivered competitive high returns based on long term capital appreciation. This analysis will use hvplots visualizations to plot the top 15 REITS by market CAP, calculate rolling statistics, betas and compare them to the trends of S&P 500 market Cap index over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hvplot\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../Resources/REITmarketcap.csv does not exist: '../../Resources/REITmarketcap.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd9cf1bea950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read in the CSV as a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mREIT_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Grab the symbol, volue and price per earning ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/alpacaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/alpacaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/alpacaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/alpacaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/alpacaenv/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../Resources/REITmarketcap.csv does not exist: '../../Resources/REITmarketcap.csv'"
     ]
    }
   ],
   "source": [
    "# Set the path\n",
    "file_path = Path('../../Resources/REITmarketcap.csv')\n",
    "\n",
    "# Read in the CSV as a DataFrame\n",
    "REIT_csv = pd.read_csv(file_path)\n",
    "\n",
    "#Grab the symbol, volue and price per earning ratio\n",
    "Volume_PE = REIT_csv.loc[:, ['Symbol','Volume', 'PE Ratio (TTM)']]\n",
    "\n",
    "#Set the Symbol as index\n",
    "Volume_PE.set_index(Volume_PE[\"Symbol\"], inplace=True)\n",
    "\n",
    "#Drop the extra symbol column\n",
    "Volume_PE.drop(columns=[\"Symbol\"], inplace=True)\n",
    "\n",
    "# Grab the `Symbol` and `Market Cap` columns\n",
    "market_cap = REIT_csv.loc[:, ['Symbol', 'Market Cap']]\n",
    "\n",
    "# Set the 'Symbol' as the index\n",
    "market_cap.set_index(market_cap['Symbol'], inplace=True)\n",
    "\n",
    "# Drop the extra 'Symbol' column\n",
    "market_cap.drop(columns=['Symbol'], inplace=True)\n",
    "\n",
    "# Filter down to 15 companies with the largest market caps\n",
    "top_15_market_cap = market_cap.nlargest(15,'Market Cap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REIT_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot top 5 REIT Stocks all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot TOP 5 REIT all variables\n",
    "REIT_csv.set_index(REIT_csv[\"Symbol\"], inplace=True)\n",
    "REIT_csv.head(5).hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create line Plot of top 15 REITS by Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate standard hvplot to plot top 15 REITS by market cap\n",
    "top_15_market_cap.hvplot(title='Top 15 Market Cap REIT Companies (in billions)', color= \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Create a bar Plot of top 15 REITS by Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a hvplot bar chart of the top 15 market cap companies\n",
    "top_15_market_cap.hvplot.bar(title='Top 15 Market Cap REIT Companies (in billions)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the relationship between volume of transactions and price per earnings\n",
    "Volume_PE.hvplot(kind= 'scatter', x='Volume', y='PE Ratio (TTM)', color= \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean the data of 3 largest REIT stocks by Market Cap\n",
    "## Set the file paths for the CSVs using the Path class from the pathlib library\n",
    "\n",
    "Used adj. close price to factor dividends in the calculations, because by law REITs are required to pay out at tleast 90% of their taxable income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../../Resources/PLD.csv')\n",
    "\n",
    "# Read in the CSV as a DataFrame\n",
    "PLD_csv = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../../Resources/CCI.csv')\n",
    "\n",
    "# Read in the CSV as a DataFrame\n",
    "CCI_csv = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('../../Resources/AMT.csv')\n",
    "\n",
    "# Read in the CSV as a DataFrame\n",
    "AMT_csv = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([PLD_csv, CCI_csv, AMT_csv], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "# Sort datetime index in ascending order (past to present)\n",
    "combined_df.sort_index(inplace=True)\n",
    "\n",
    "# Display a few rows\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns = ['PLD', 'CCI', 'AMT']\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `pct_change` function to calculate daily returns of closing prices for each column\n",
    "daily_returns = combined_df.pct_change().dropna()\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `dot` function to multiply the weights by each stock's daily return to get the portfolio daily return\n",
    "weights = [0.3, 0.3, 0.3]\n",
    "\n",
    "portfolio_returns = daily_returns.dot(weights)\n",
    "portfolio_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `plot` function to plot the daily portfolio returns\n",
    "portfolio_returns.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `cumprod` function to cumulatively multiply each element in the Series by it's preceding element until the end\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod() - 1\n",
    "cumulative_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `plot` function to plot the cumulative portfolio returns\n",
    "cumulative_returns.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling statistics REITS Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a rolling 7-day mean of REIT's closing prices\n",
    "combined_df.rolling(window=7).mean().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a rolling 7-day std dev of REITS's closing prices\n",
    "combined_df.rolling(window=7).std().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a rolling 30-day mean of MSFT's closing prices\n",
    "combined_df.rolling(window=30).mean().hvplot.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a rolling 30-day std dev of MSFT's closing prices\n",
    "combined_df.rolling(window=30).std().hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read S$P 500 Data and calculate daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in S&P 500 Market Cap index\n",
    "file_path = Path('../../Resources/SPindex.csv')\n",
    "\n",
    "# Read in the CSV as a DataFrame\n",
    "sp500_df = pd.read_csv(file_path, index_col=\"Date\", parse_dates=True, infer_datetime_format=True)\n",
    "sp500_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate S&P 500 Daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `pct_change` function to calculate daily returns of closing prices for each column\n",
    "SP500_daily_returns = sp500_df.pct_change().dropna()\n",
    "SP500_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot S&P 500 daily returns\n",
    "SP500_daily_returns.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine REIT`S Stock with S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pivot table where the columns are the closing prices for each ticker\n",
    "new_combined_df = pd.concat([PLD_csv, CCI_csv, AMT_csv, sp500_df], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "# Sort datetime index in ascending order (past to present)\n",
    "new_combined_df.sort_index()\n",
    "\n",
    "# Set column names to 'FB' 'TWTR', 'SNAP', and 'S&P 500'\n",
    "new_combined_df.columns = [\"PLD\", \"CCI\", \"AMT\", \"S&P 500\"]\n",
    "\n",
    "# Display a few rows\n",
    "new_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate new daily returns\n",
    "# Use the `pct_change` function to calculate daily returns of closing prices for each column\n",
    "new_daily_returns = new_combined_df.pct_change().dropna()\n",
    "new_daily_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Covariance of REITS Stock Returns vs. S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of all daily returns of social media stocks vs. S&P 500\n",
    "pld_covariance = new_daily_returns['PLD'].cov(new_daily_returns['S&P 500'])\n",
    "cci_covariance = new_daily_returns['CCI'].cov(new_daily_returns['S&P 500'])\n",
    "amt_covariance = new_daily_returns['AMT'].cov(new_daily_returns['S&P 500'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Variance of S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance of all daily returns of social media stocks vs. S&P 500\n",
    "variance = new_daily_returns['S&P 500'].var()\n",
    "variance\n",
    "\n",
    "#High variance in stocks are usually associated with high risk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Beta Values of REIT Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate beta of all daily returns of social media stocks\n",
    "pld_beta = pld_covariance / variance\n",
    "cci_beta = cci_covariance / variance\n",
    "amt_beta = amt_covariance / variance\n",
    "\n",
    "print(f\"PLD: {pld_beta} | CCI: {cci_beta} | AMT: {amt_beta}\")\n",
    "\n",
    "#Betas below 1.0 usially tell that the stocs are less volatile than the market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 30-Day Rolling Betas of REIT Stock Returns vs. S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 30-day rolling covariance of REIT vs. S&P 500 and plot the data\n",
    "rolling_pld_covariance = new_daily_returns['PLD'].rolling(window=30).cov(new_daily_returns['S&P 500'])\n",
    "rolling_cci_covariance = new_daily_returns['CCI'].rolling(window=30).cov(new_daily_returns['S&P 500'])\n",
    "rolling_amt_covariance = new_daily_returns['AMT'].rolling(window=30).cov(new_daily_returns['S&P 500'])\n",
    "\n",
    "# Calculate 30-day rolling variance of S&P 500\n",
    "rolling_variance = new_daily_returns['S&P 500'].rolling(window=30).var()\n",
    "\n",
    "# Calculate 30-day rolling beta of REIT and plot the data\n",
    "rolling_pld_beta = rolling_pld_covariance / rolling_variance\n",
    "rolling_cci_beta = rolling_cci_covariance / rolling_variance\n",
    "rolling_amt_beta = rolling_amt_covariance / rolling_variance\n",
    "rolling_amt_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Rolling 30-Day Betas of REIT Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure and plot the different datasets as multiple trends on the same figure\n",
    "ax = rolling_pld_beta.plot(figsize=(20, 10), title='Rolling 30-Day Beta of REITS stocks')\n",
    "rolling_cci_beta.plot(ax=ax)\n",
    "rolling_amt_beta.plot(ax=ax)\n",
    "\n",
    "\n",
    "# Set the legend of the figure\n",
    "ax.legend([\"PLD\", \"CCI\", \"AMT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Based on the above calculation, we concluded that S&P 500 market cap index are riskier than the three REIT stocks, although the potential for higher returns is greater. Depending on risk tolerance, for risky averse investors, investing in REITS can be a better option, while those seeking higher return may opt to invest in S&P 500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpacaenv",
   "language": "python",
   "name": "alpacaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
